{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28",
      "name": "model arsitektur VGG16.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arfianaja/training/blob/main/model_arsitektur_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "roFwivGqztKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sn;\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
      ],
      "metadata": {
        "id": "XlyVnLpU3ihk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/yoga/dataawan.zip'"
      ],
      "metadata": {
        "id": "mADizBXwEXqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['cumulonimbus', 'cumulus', 'stratocumulus','nimbostratus', 'stratus']\n",
        "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "nb_classes = len(class_names)\n",
        "\n",
        "IMAGE_SIZE = (224, 224)"
      ],
      "metadata": {
        "id": "LYLBtFWm3ifM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    datasets = [r'/content/dataset_awan',\n",
        "                r'/content/dataset_awan']\n",
        "    output = []\n",
        "\n",
        "    for dataset in datasets:\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        print(\"Loading {}\".format(dataset))\n",
        "\n",
        "        # Iterate through each folder corresponding to a category\n",
        "        for folder in os.listdir(dataset):\n",
        "            label = class_names_label[folder]\n",
        "\n",
        "            # Iterate through each image in our folder\n",
        "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
        "\n",
        "                # Get the path name of the image\n",
        "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
        "\n",
        "                # Open and resize the img\n",
        "                image = cv2.imread(img_path)\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                image = cv2.resize(image, IMAGE_SIZE)\n",
        "\n",
        "                # Append the image and its corresponding label to the output\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "        images = np.array(images, dtype = 'float32')\n",
        "        labels = np.array(labels, dtype = 'int32')\n",
        "\n",
        "        output.append((images, labels))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "RXVTV5Ql3iZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = load_data()"
      ],
      "metadata": {
        "id": "ubw97gbI3iUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, train_labels = shuffle(train_images, train_labels, random_state=5)"
      ],
      "metadata": {
        "id": "taRF4c_e3iP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = train_images.shape[0]\n",
        "n_test = test_images.shape[0]\n",
        "\n",
        "print(\"Training Examples = {}\".format(n_train))\n",
        "print(\"Testing Examples = {}\".format(n_test))\n",
        "print(\"Image Size = {}\".format(IMAGE_SIZE))"
      ],
      "metadata": {
        "id": "YWeRLpUp4JSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "_,train_counts = np.unique(train_labels, return_counts=True)\n",
        "_,test_counts = np.unique(test_labels, return_counts=True)\n",
        "\n",
        "pd.DataFrame({'train':train_counts, 'test':test_counts}, index=class_names).plot.bar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B0_dMSTU4Ntf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie(train_counts, labels=class_names, autopct='%1.1f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "92rP9uS04TXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling the data,\n",
        "train_images /= 255.0\n",
        "test_images /= 255.0"
      ],
      "metadata": {
        "id": "OWqVEbUm47bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_random_image(class_names, images, labels):\n",
        "    index = np.random.randint(images.shape[0])\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(images[index])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.title(\"Image #{}\".format(index+1)+\" \"+class_names[labels[index]])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lfMMqqiqIo21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_random_image(class_names, train_images, train_labels)"
      ],
      "metadata": {
        "id": "-0uF-39JIsjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_examples(class_names, images, labels):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    fig.suptitle(\"Examples\",fontsize=12)\n",
        "    for i in range(25):\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.xlabel(class_names[labels[i]])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "fVwRHm71le2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_examples(class_names, train_images, train_labels)"
      ],
      "metadata": {
        "id": "--vs4E03lejI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "model = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "JGhLeMDnqz3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = model.predict(train_images)\n",
        "test_features = model.predict(test_images)"
      ],
      "metadata": {
        "id": "5f6Ufkffq54d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the VGG16 model without the top classification layer\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze early layers, unfreeze later ones (adjust as needed)\n",
        "for layer in vgg16_base.layers[:-5]:  # Example: unfreeze the last 5 layers\n",
        "    layer.trainable = False\n",
        "\n",
        "# Define the new model on top of the VGG16 base\n",
        "model = Sequential([\n",
        "    vgg16_base,\n",
        "    Flatten(),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile and train the model using the original images (224, 224, 3)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=32, epochs=30, validation_split=0.3)"
      ],
      "metadata": {
        "id": "srFj0T0nq5xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracy_history(history):\n",
        "    \"\"\"\n",
        "        Plot the accuracy and the loss during the training of the nn.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(10,5))\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(221)\n",
        "    plt.plot(history.history['accuracy'],'bo--', label = \"accuracy\")\n",
        "    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_accuracy\")\n",
        "    plt.title(\"train_accuracy vs val_accuracy\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot loss function\n",
        "    plt.subplot(222)\n",
        "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
        "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
        "    plt.title(\"train_loss vs val_loss\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZWxI6lFBRX0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracy_history(history)"
      ],
      "metadata": {
        "id": "Q_ZtzilCq5u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Prediksi label untuk data uji\n",
        "test_predictions = model.predict(test_images)  # Use original test images\n",
        "test_predictions_labels = np.argmax(test_predictions, axis=1)\n",
        "\n",
        "# Buat confusion matrix\n",
        "cm = confusion_matrix(test_labels, test_predictions_labels)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V8QzYnLFLA7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "test_prediction = model.predict(test_images)\n",
        "test_prediction_label = np.argmax(test_prediction, axis=1)\n",
        "print(classification_report(test_labels, test_prediction_label))"
      ],
      "metadata": {
        "id": "GBquzpxMTo3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.input_shape)"
      ],
      "metadata": {
        "id": "6382JdZ_S0Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "class_names = ['cumulonimbus', 'cumulus', 'stratocumulus','nimbostratus', 'stratus']\n",
        "def awan_prediction(new_image):\n",
        "    # Muat dan preprocess gambar\n",
        "    img = image.load_img(new_image, target_size=(224, 224)) # Load image\n",
        "    img_array = image.img_to_array(img) # Convert to numpy array\n",
        "    img_array = np.expand_dims(img_array, axis=0) # Add batch dimension\n",
        "    img_array = preprocess_input(img_array) # Preprocess for VGG16\n",
        "\n",
        "    # Tampilkan gambar\n",
        "    test_image = image.load_img(new_image, target_size=(224, 224))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(test_image)\n",
        "    plt.show()\n",
        "\n",
        "    # Ekstraksi fitur dari VGG16\n",
        "    features = vgg16_model.predict(img_array)\n",
        "\n",
        "    # Prediksi label menggunakan model yang telah dilatih\n",
        "    predicted_array = model.predict(features)\n",
        "    pred_labels = class_names[np.argmax(predicted_array)]\n",
        "    predicted_accuracy = round(np.max(predicted_array) * 100, 2)\n",
        "\n",
        "    print(\"awan is\", pred_labels, \"with\", predicted_accuracy, \"% accuracy\")\n",
        "\n",
        "# Path ke gambar yang ingin diprediksi\n",
        "# awan_prediction(\"/content/drive/MyDrive/DATA/awan-original/stratus/stratus (104).jpg\")\n",
        "# awan_prediction(\"/content/drive/MyDrive/DATA/awan-original/cumulonimbus/cumulonimbus (105).jpg\")\n",
        "# awan_prediction(\"/content/drive/MyDrive/DATA/awan/test/cumulus/cumulus-308-_jpg.rf.be00cc11aeb55e015411b74cbd745f8e.jpg\")\n",
        "#awan_prediction(\"/content/drive/MyDrive/DATA/awan-original/stratus/stratus (104).jpg\")\n",
        "awan_prediction(\"/content/dataset_awan/cumulonimbus/cumulonimbus (1)_11zon.jpg\")"
      ],
      "metadata": {
        "id": "7ntgdxb8R2Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "model.save('model-vgg16.h5')"
      ],
      "metadata": {
        "id": "s6-4BX3pEvVs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}